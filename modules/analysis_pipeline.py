import streamlit as st
import pandas as pd
from typing import Dict, Any, Optional
import json
from datetime import datetime
import random
import time
import re
from collections import Counter
from concurrent.futures import ThreadPoolExecutor, as_completed
from langchain_openai import ChatOpenAI
from modules.profiling_module import AnalysisPlan, validate_plan
from modules.ui_components import display_analysis_plan, display_plan_review_interface, feedback_input_interface
from modules.categorize import generate_wordcloud_from_freq, categorize_keywords_batch
from modules.summary_module import generate_summary_with_gpt 
from modules.sentiment_module import merge_sentiment_results, refine_neutral_keywords_with_gpt, analyze_sentiment_with_finbert, summarize_sentiment_by_category

class AnalysisPipeline:
    """ë¶„ì„ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.planner = AnalysisPlan()
        self.reset_session_state()
    
    def reset_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'analysis_plan' not in st.session_state:
            st.session_state.analysis_plan = None
        if 'plan_approved' not in st.session_state:
            st.session_state.plan_approved = False
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
        if 'current_step' not in st.session_state:
            st.session_state.current_step = 1
            
    def _display_summary_results(self, summary_result: dict) -> str:
        return summary_result.get("summary", "")

    def _display_sentiment_results(self, sentiment_result: dict) -> pd.DataFrame:
        return sentiment_result.get("summary_df")

    def _display_keyword_results(self, keyword_result: dict) -> pd.DataFrame:
        freq_df = keyword_result.get("freq_df")  # 'freq_df' í‚¤ë¡œ ì €ì¥ëœ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        if isinstance(freq_df, pd.DataFrame):
            return freq_df
        return pd.DataFrame()
    
    def step1_generate_plan(self, data: pd.DataFrame, description: str):
        """1ë‹¨ê³„: ë¶„ì„ ê¸°íšì„œ ìƒì„±"""
        st.header("1ï¸âƒ£ ìŠ¤ë§ˆíŠ¸ AI ë¶„ì„ ê¸°íšì„œ ìƒì„±")  # ì œëª© ë³€ê²½
        
        # col1, col2 = st.columns([2, 1])
        
        # with col1:
        #     st.write("**ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**")
        #     st.dataframe(data.head())
        
        # with col2:
        #     st.write("**ë°ì´í„° ì •ë³´**")
        #     st.write(f"- í–‰ ìˆ˜: {len(data):,}")
        #     st.write(f"- ì»¬ëŸ¼ ìˆ˜: {len(data_subjectdata.columns)}")
        #     st.write(f"- ì»¬ëŸ¼: {', '.join(data.columns[:3])}{'...' if len(data.columns) > 3 else ''}")
        
        # st.write("**ë°ì´í„° ì„¤ëª…**")
        # st.write(description)
        
        # ê¸°íšì„œ ìƒì„± ë²„íŠ¼
        if st.button("ğŸ¤– AI ë¶„ì„ ê³„íš ìƒì„± (ê°•í™”ë²„ì „)", type="primary", use_container_width=True):  # ë²„íŠ¼ëª… ë³€ê²½
            with st.spinner("ğŸ§  AIê°€ ë°ì´í„°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ê³„íšì„ ìˆ˜ë¦½ ì¤‘..."):  # ë©”ì‹œì§€ ë³€ê²½
                plan = self.planner.generate_initial_plan(data, description)
                st.session_state.analysis_plan = plan
                st.session_state.plan_approved = False
                st.session_state.current_step = 2
                st.rerun()
        
        # ê¸°íšì„œê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.analysis_plan:
            st.write("---")
            display_analysis_plan(st.session_state.analysis_plan)
            return True
        return False
    
    def step2_review_plan(self):
        """2ë‹¨ê³„: ê¸°íšì„œ ê²€í†  ë° ìˆ˜ì •"""
        if not st.session_state.analysis_plan:
            st.warning("ë¨¼ì € ë¶„ì„ ê¸°íšì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return False
            
        st.header("2ï¸âƒ£ ê¸°íšì„œ ê²€í†  ë° ìˆ˜ì •")
        
        # í˜„ì¬ ê¸°íšì„œ í‘œì‹œ
        display_analysis_plan(st.session_state.analysis_plan)
        
        st.write("---")
        
        # ê²€ì¦ ê²°ê³¼ í‘œì‹œ
        validation_passed = display_plan_review_interface(st.session_state.analysis_plan)
        
        # í”¼ë“œë°± ì…ë ¥ ì„¹ì…˜
        st.write("### ğŸ“ ê¸°íšì„œ ìˆ˜ì •")
        feedback = feedback_input_interface()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("âœï¸ ê¸°íšì„œ ìˆ˜ì •", use_container_width=True) and feedback:
                with st.spinner("í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ê¸°íšì„œë¥¼ ìˆ˜ì •ì¤‘ì…ë‹ˆë‹¤..."):
                    revised_plan = self.planner.revise_plan_with_feedback(
                        st.session_state.analysis_plan, feedback
                    )
                    st.session_state.analysis_plan = revised_plan
                    st.rerun()
        
        with col2:
            if st.button("ğŸ”„ ê¸°íšì„œ ì¬ìƒì„±", use_container_width=True):
                st.session_state.analysis_plan = None
                st.session_state.current_step = 1
                st.rerun()
        
        with col3:
            approved = st.button("âœ… ê¸°íšì„œ ìŠ¹ì¸", type="primary", use_container_width=True)
                
        # âœ… í•œ ì¤„ ì•„ë˜ì— ìŠ¹ì¸ ë©”ì‹œì§€ ì¶œë ¥
        if approved and validation_passed:
            st.session_state.plan_approved = True
            st.session_state.current_step = 3
            st.success("ğŸ‰ ê¸°íšì„œê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤! ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.rerun()
            
        return st.session_state.plan_approved
    
    def step3_execute_analysis(self, data: pd.DataFrame):
        """3ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰"""
        if not st.session_state.plan_approved:
            st.warning("ë¨¼ì € ê¸°íšì„œë¥¼ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.")
            return False
            
        st.header("3ï¸âƒ£ ë¶„ì„ ì‹¤í–‰")
        
        # ë¶„ì„ ì‹¤í–‰ ì •ë³´ í‘œì‹œ
        plan = st.session_state.analysis_plan
        modules = plan["recommended_modules"]
        
        st.write("**ì‹¤í–‰ ì˜ˆì • ë¶„ì„**")
        execution_list = []
        if modules["sentiment_analysis"]["use"]:
            execution_list.append("ğŸ˜Š ê°ì • ë¶„ì„")
        if modules["keyword_analysis"]["use"]:
            execution_list.append("ğŸ”¤ í‚¤ì›Œë“œ ë¶„ì„")
        if modules["summary_analysis"]["use"]:
            execution_list.append("ğŸ“ ìš”ì•½ ë¶„ì„")
        
        for item in execution_list:
            st.write(f"- {item}")
        
        if not execution_list:
            st.error("ì‹¤í–‰í•  ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°íšì„œë¥¼ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.")
            return False
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            results = self._run_analysis(data, plan)
            
            if results:
                st.session_state.analysis_results = results
                st.session_state.current_step = 4
                st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                return False
        
        return False
    
    def step4_display_results(self):
        """4ë‹¨ê³„: ê²°ê³¼ í‘œì‹œ"""
        if not st.session_state.analysis_results:
            st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        st.header("4ï¸âƒ£ ë¶„ì„ ê²°ê³¼")
        results = st.session_state.analysis_results
        
        # ê²°ê³¼ ê°œìš”
        st.write("### ğŸ“Š ë¶„ì„ ê°œìš”")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë¶„ì„ ì™„ë£Œ ì‹œê°„", results.get("timestamp", "Unknown"))
        with col2:
            st.metric("ì†Œìš” ì‹œê°„", results.get("elapsed_time", "Unknown"))
        with col3:
            st.metric("ë¶„ì„ëœ ëª¨ë“ˆ ìˆ˜", len([k for k, v in results.items() if k.endswith("_analysis")]))
        with col4:
            if "keyword_analysis" in results:
                keyword_count = len(results["keyword_analysis"].get("keywords", []))
                st.metric("ì¶”ì¶œëœ í‚¤ì›Œë“œ ìˆ˜", keyword_count)
                            
        # ê° ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if "sentiment_analysis" in results:
            self._display_sentiment_results(results["sentiment_analysis"])
        
        if "keyword_analysis" in results:
            self._display_keyword_results(results["keyword_analysis"])
        
        if "summary_analysis" in results:
            self._display_summary_results(results["summary_analysis"])
        
    
    def _run_analysis(self, data: pd.DataFrame, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ğŸš€ ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰ (ì „ì²´ ë°ì´í„°)"""
        results = {}
        
        # ë¶„ì„ ëŒ€ìƒ ë°ì´í„° ì¤€ë¹„
        target_data = self._prepare_analysis_data(data, plan)
        
        if target_data is None or target_data.empty:
            st.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        modules = plan["recommended_modules"]
        total_steps = sum(1 for module in modules.values() if module["use"])
        
        if total_steps == 0:
            st.error("ì‹¤í–‰í•  ë¶„ì„ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            start_time = time.time()
            
            # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  ë¶„ì„ ë™ì‹œ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = {}
                
                # ê° ë¶„ì„ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                if modules["keyword_analysis"]["use"]:
                    futures["keyword"] = executor.submit(
                        self.keyword_analysis,
                        target_data, modules["keyword_analysis"]["target_columns"]
                    )
                
                if modules["sentiment_analysis"]["use"]:
                    futures["sentiment"] = executor.submit(
                        self._run_sentiment_analysis_fast,
                        target_data, modules["sentiment_analysis"]["target_columns"]
                    )
                
                if modules["summary_analysis"]["use"]:
                    futures["summary"] = executor.submit(
                        self._run_summary_analysis_fast,
                        target_data, modules["summary_analysis"]["target_columns"]
                    )
                
                # ê²°ê³¼ ìˆ˜ì§‘
                completed_count = 0
                for analysis_type, future in futures.items():
                    status_text.text(f"âš¡ {analysis_type} ë¶„ì„ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                    
                    try:
                        result = future.result(timeout=60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                        results[f"{analysis_type}_analysis"] = result
                        completed_count += 1
                        progress_bar.progress(completed_count / len(futures))
                        st.success(f"âœ… {analysis_type} ë¶„ì„ ì™„ë£Œ!")
                    except Exception as e:
                        st.error(f"âŒ {analysis_type} ë¶„ì„ ì‹¤íŒ¨: {e}")
                        results[f"{analysis_type}_analysis"] = {"error": str(e)}
                        completed_count += 1
                        progress_bar.progress(completed_count / len(futures))
            
            progress_bar.progress(1.0)
            elapsed_time = time.time() - start_time
            status_text.text(f"âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)")
            
            # ê²°ê³¼ì— ë©”íƒ€ ì •ë³´ ì¶”ê°€
            results["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            results["plan"] = plan
            results["elapsed_time"] = f"{elapsed_time:.1f}ì´ˆ"
            
            return results
            
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def _prepare_analysis_data(self, data: pd.DataFrame, plan: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """ğŸš€ ë³‘ë ¬ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (ì „ì²´ ë°ì´í„°)"""
        
        # ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼ë“¤ ìˆ˜ì§‘
        target_columns = set()
        modules = plan["recommended_modules"]
        
        st.write("**ë¶„ì„ ëª¨ë“ˆë³„ ëŒ€ìƒ ì»¬ëŸ¼:**")
        for module_name, module_info in modules.items():
            if module_info["use"]:
                cols = module_info["target_columns"]
                target_columns.update(cols)
                st.write(f"- {module_name}: {cols}")
        
        if not target_columns:
            st.error("âŒ ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ëŒ€ìƒ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ìˆëŠ”ì§€ í™•ì¸
        available_columns = [col for col in target_columns if col in data.columns]
        missing_columns = [col for col in target_columns if col not in data.columns]
        
        st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:** {available_columns}")
        if missing_columns:
            st.warning(f"âš ï¸ ë°ì´í„°ì— ì—†ëŠ” ì»¬ëŸ¼: {missing_columns}")
        
        if not available_columns:
            st.error("âŒ ë¶„ì„ ê°€ëŠ¥í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° í•„í„°ë§ (ìƒ˜í”Œë§ ì œê±°)
        filtered_data = data[available_columns].copy()
        
        # ëª¨ë“  ì»¬ëŸ¼ì´ ë¹ˆ ê°’ì¸ í–‰ë§Œ ì œê±°
        filtered_data = filtered_data.dropna(how='all')
        
        if filtered_data.empty:
            st.error("âŒ í•„í„°ë§ í›„ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        st.success(f"âœ… ì „ì²´ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ: {len(filtered_data)}í–‰, {len(available_columns)}ê°œ ì»¬ëŸ¼")
        st.info("ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        return filtered_data
    
    def _run_keyword_analysis_fast(self, data: pd.DataFrame, target_columns: list) -> Dict[str, Any]:
        """ğŸš€ ë³‘ë ¬ í‚¤ì›Œë“œ ë¶„ì„ (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        
        # ğŸ” ìƒì„¸í•œ ì§„í–‰ ìƒí™© í‘œì‹œ
        st.write("ğŸ”‘ **í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘**")
        progress_container = st.empty()
        
        try:
            # 1ë‹¨ê³„: LLM ì´ˆê¸°í™”
            progress_container.write("ğŸ¤– 1/5 ë‹¨ê³„: LLM ì´ˆê¸°í™” ì¤‘...")
            
            try:
                llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    openai_api_key=st.secrets["your_section"]["api_key"],
                    temperature=0
                )
                progress_container.write("   âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                error_msg = f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨:\n{str(e)}\nAPI í‚¤ì™€ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.error(error_msg)
                return {"error": error_msg, "texts_analyzed": 0}
            
            # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
            progress_container.write("ğŸ“Š 2/5 ë‹¨ê³„: í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            texts = []
            for col in target_columns:
                if col in data.columns:
                    valid_texts = data[col].dropna().astype(str)
                    valid_texts = valid_texts[valid_texts.str.strip() != '']
                    texts.extend(valid_texts.tolist())
                    progress_container.write(f'   - [{col}] ì»¬ëŸ¼ì—ì„œ í…ìŠ¤íŠ¸ {len(valid_texts):,}ê°œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘')
            
            if not texts:
                error_msg = f"âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\nëŒ€ìƒ ì»¬ëŸ¼: {target_columns}\nê° ì»¬ëŸ¼ì˜ ë°ì´í„° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.error(error_msg)
                return {"error": error_msg, "texts_analyzed": 0}
            
            # 3ë‹¨ê³„: ë°ì´í„° í¬ê¸° ë° í’ˆì§ˆ ê²€ì¦
            progress_container.write(f"ğŸ“ 3/5 ë‹¨ê³„: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ({len(texts):,}ê°œ í…ìŠ¤íŠ¸)")
            
            # í…ìŠ¤íŠ¸ í‰ê·  ê¸¸ì´ ê³„ì‚°
            avg_length = sum(len(str(text)) for text in texts) / len(texts)
            progress_container.write(f"   í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {avg_length:.1f}ì")
            
            if avg_length < 10:
                st.warning("âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ì¶”ì¶œ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            if len(texts) > 500:
                st.warning(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë§ìŠµë‹ˆë‹¤ ({len(texts):,}ê°œ). ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # 4ë‹¨ê³„: í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
            progress_container.write("ğŸ“¦ 4/5 ë‹¨ê³„: í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ì¤‘...")
            
            try:
                from modules.categorize import extract_keywords_parallel
                progress_container.write("   âœ… í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
            except ImportError as e:
                error_msg = f"âŒ í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n{str(e)}\n'modules/categorize.py' íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.error(error_msg)
                return {"error": error_msg, "texts_analyzed": len(texts)}
            
            # 5ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰
            progress_container.write("ğŸ”„ 5/5 ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰ ì¤‘...")
            
            try:
                # ğŸ”§ ì•ˆì „í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì²­í¬ í¬ê¸°ì™€ ì›Œì»¤ ìˆ˜ ì¡°ì •)
                chunk_size = min(20, max(5, len(texts) // 10))  # ë™ì  ì²­í¬ í¬ê¸°
                max_workers = min(3, max(1, len(texts) // 100))  # ë™ì  ì›Œì»¤ ìˆ˜
                
                progress_container.write(f"   ì„¤ì •: ì²­í¬ í¬ê¸°={chunk_size}, ì›Œì»¤ ìˆ˜={max_workers}")
                
                keywords = extract_keywords_parallel(texts, llm, chunk_size=chunk_size, max_workers=max_workers)
                
                if not keywords:
                    error_msg = "âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\nê°€ëŠ¥í•œ ì›ì¸:\n- API í˜¸ì¶œ ì‹¤íŒ¨\n- í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¬¸ì œ\n- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ"
                    st.error(error_msg)
                    return {"error": error_msg, "texts_analyzed": len(texts)}
                
                # ì„±ê³µ ë©”ì‹œì§€
                progress_container.write(f"âœ… í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ! ì¶”ì¶œëœ í‚¤ì›Œë“œ: {len(keywords):,}ê°œ")
                
                return {
                    "keywords": keywords,
                    "texts_analyzed": len(texts),
                    "avg_text_length": avg_length,
                    "chunk_size": chunk_size,
                    "max_workers": max_workers,
                    "status": "completed",
                    "method": "parallel_extraction"
                }
                
            except Exception as e:
                error_msg = f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{str(e)}\n\nìƒì„¸ ì •ë³´:\n- í…ìŠ¤íŠ¸ ìˆ˜: {len(texts):,}\n- í‰ê·  ê¸¸ì´: {avg_length:.1f}ì\n- ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}"
                st.error(error_msg)
                return {"error": error_msg, "texts_analyzed": len(texts)}
                
        except Exception as e:
            error_msg = f"âŒ í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜:\n{str(e)}\n\nì „ì²´ ìŠ¤íƒ:\n{type(e).__name__}: {str(e)}"
            st.error(error_msg)
            progress_container.empty()
            return {"error": error_msg, "texts_analyzed": 0}

    
    def _run_sentiment_analysis_fast(self, data: pd.DataFrame, target_columns: list) -> Dict[str, Any]:
        """ğŸš€ ê°ì • ë¶„ì„ (ìš”ì•½ ê¸°ë°˜)"""
        try:
            # LLM ì´ˆê¸°í™”
            try:
                llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    openai_api_key=st.secrets["your_section"]["api_key"],
                    temperature=0
                )
            except Exception as e:
                return {"error": f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", "texts_analyzed": 0}

            # í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            texts = []
            for col in target_columns:
                if col in data.columns:
                    valid_texts = data[col].dropna().astype(str)
                    valid_texts = valid_texts[valid_texts.str.strip() != '']
                    texts.extend(valid_texts.tolist())

            if not texts:
                return {"error": "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.", "texts_analyzed": 0}
            
           

            # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (í•„ìˆ˜)
            categorized_df = categorize_keywords_batch(texts, llm)


            # ê°ì • ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸
            sentiment_df, _, categorized_df = analyze_sentiment_with_finbert(texts, llm)  # llm ì—†ì´ ì§„í–‰
            refined_df = refine_neutral_keywords_with_gpt(sentiment_df, None)
            updated_df = merge_sentiment_results(sentiment_df, refined_df)
            summary = summarize_sentiment_by_category(categorized_df, updated_df)

            return {
                "summary_df": summary,  # PieChartìš© ê°ì • ë¶„í¬
                "updated_sentiment_df": updated_df,
                "texts_analyzed": len(texts),
                "status": "completed"
            }

        except Exception as e:
            return {"error": str(e), "texts_analyzed": 0}

    def _run_keyword_analysis_fast(self, data: pd.DataFrame, target_columns: list) -> Dict[str, Any]:
        """ğŸš€ ë³‘ë ¬ í‚¤ì›Œë“œ ë¶„ì„ (ìŠ¤ë ˆë“œ ì•ˆì „ ë²„ì „)"""
        
        try:
            # LLM ì´ˆê¸°í™”
            try:
                llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    openai_api_key=st.secrets["your_section"]["api_key"],
                    temperature=0
                )
            except Exception as e:
                return {"error": f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", "texts_analyzed": 0}
            
            # í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
            texts = []
            for col in target_columns:
                if col in data.columns:
                    valid_texts = data[col].dropna().astype(str)
                    valid_texts = valid_texts[valid_texts.str.strip() != '']
                    texts.extend(valid_texts.tolist())
            
            if not texts:
                return {"error": "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.", "texts_analyzed": 0}
            
            # í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì¦
            avg_length = sum(len(str(text)) for text in texts) / len(texts)
            
            # í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ
            try:
                from modules.categorize import extract_keywords_parallel
            except ImportError as e:
                return {"error": f"í‚¤ì›Œë“œ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", "texts_analyzed": len(texts)}
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰
            try:
                chunk_size = min(20, max(5, len(texts) // 10))
                max_workers = min(2, max(1, len(texts) // 100))  # ì›Œì»¤ ìˆ˜ ì¤„ì„
                
                keywords = extract_keywords_parallel(texts, llm, chunk_size=chunk_size, max_workers=max_workers)
                
                if not keywords:
                    return {"error": "í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "texts_analyzed": len(texts)}
                
                return {
                    "keywords": keywords,
                    "texts_analyzed": len(texts),
                    "avg_text_length": avg_length,
                    "chunk_size": chunk_size,
                    "max_workers": max_workers,
                    "status": "completed",
                    "method": "thread_safe_extraction"
                }
                
            except Exception as e:
                return {"error": f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}", "texts_analyzed": len(texts)}
            
        except Exception as e:
            return {"error": str(e), "texts_analyzed": 0}

    def _run_summary_analysis(self, data: pd.DataFrame, target_columns: list) -> Dict[str, Any]:
        """ğŸ“ ìš”ì•½ ë¶„ì„ (ìŠ¤ë ˆë“œ ì•ˆì „ ë²„ì „)"""
        
        try:
            # í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
            texts = []
            for col in target_columns:
                if col in data.columns:
                    valid_texts = data[col].dropna().astype(str)
                    valid_texts = valid_texts[valid_texts.str.strip() != '']
                    texts.extend(valid_texts.tolist())
            
            if not texts:
                return {"error": "ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.", "texts_analyzed": 0}
            
            # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            total_length = sum(len(str(text)) for text in texts)
            avg_length = total_length / len(texts)
            
            # ìš”ì•½ ëª¨ë“ˆ ë¡œë“œ
            try:
                from modules.summary_module import generate_summary_with_gpt
            except ImportError as e:
                return {"error": f"ìš”ì•½ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", "texts_analyzed": len(texts)}
            
            # ìš”ì•½ ì‹¤í–‰
            try:
                summary = generate_summary_with_gpt(texts)
                
                if not summary or len(str(summary).strip()) < 10:
                    return {"error": "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "texts_analyzed": len(texts)}
                
                summary_length = len(str(summary))
                compression_ratio = (total_length / summary_length) if summary_length > 0 else 0
                
                return {
                    "summary": summary,
                    "texts_analyzed": len(texts),
                    "total_length": total_length,
                    "summary_length": summary_length,
                    "compression_ratio": compression_ratio,
                    "status": "completed"
                }
                
            except Exception as e:
                return {"error": f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", "texts_analyzed": len(texts)}
            
        except Exception as e:
            return {"error": str(e), "texts_analyzed": 0}

    def step3_execute_analysis(self, data: pd.DataFrame):
        """3ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰ (ìŠ¤ë ˆë“œ ì•ˆì „ UI)"""
        
        plan = st.session_state.get('analysis_plan', {})
        if not plan:
            st.error("âŒ ë¶„ì„ ê³„íšì´ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„œ ê³„íšì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        st.header("3ï¸âƒ£ AI ë¶„ì„ ì‹¤í–‰")
        
        # ë¶„ì„ ì¤€ë¹„ ì •ë³´ í‘œì‹œ
        target_columns = []
        modules = plan.get("recommended_modules", {})
        for module_name, module_info in modules.items():
            if module_info.get("use", False):
                target_columns.extend(module_info.get("target_columns", []))
        
        target_columns = list(set(target_columns))
        
        if not target_columns:
            st.error("âŒ ë¶„ì„í•  ì»¬ëŸ¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        st.write("### ğŸ“Š ë¶„ì„ ì¤€ë¹„ ì •ë³´")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì „ì²´ ë°ì´í„°", f"{len(data):,}í–‰")
        with col2:
            st.metric("ë¶„ì„ ì»¬ëŸ¼", f"{len(target_columns)}ê°œ")
        with col3:
            total_texts = sum(len(data[col].dropna()) for col in target_columns if col in data.columns)
            st.metric("ë¶„ì„ í…ìŠ¤íŠ¸", f"{total_texts:,}ê°œ")
        
        # ë¶„ì„ ì‹¤í–‰
        if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            
            st.write("### ğŸ”„ ë¶„ì„ ì§„í–‰ ìƒí™©")
            
            # ğŸ”§ UIëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ì—…ë°ì´íŠ¸
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # ë³‘ë ¬ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = {}
                
                # ğŸ”§ ìŠ¤ë ˆë“œ ì•ˆì „í•œ ë¶„ì„ í•¨ìˆ˜ë“¤ ì‹¤í–‰
                if modules.get("sentiment_analysis", {}).get("use", False):
                    futures["sentiment"] = executor.submit(self._run_sentiment_analysis_fast, data, target_columns)
                    status_placeholder.write("ğŸ˜Š ê°ì • ë¶„ì„ ì‹œì‘ë¨...")
                
                if modules.get("keyword_analysis", {}).get("use", False):
                    futures["keyword"] = executor.submit(self.keyword_analysis, data, target_columns)
                    status_placeholder.write("ğŸ”‘ í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘ë¨...")
                
                if modules.get("summary_analysis", {}).get("use", False):
                    futures["summary"] = executor.submit(self._run_summary_analysis, data, target_columns)
                    status_placeholder.write("ğŸ“ ìš”ì•½ ë¶„ì„ ì‹œì‘ë¨...")
                
                # ğŸ”§ ê²°ê³¼ ìˆ˜ì§‘ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ UI ì—…ë°ì´íŠ¸)
                results = {}
                completed_count = 0
                total_analyses = len(futures)
                
                for analysis_type, future in futures.items():
                    try:
                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                        progress_placeholder.progress(completed_count / total_analyses)
                        status_placeholder.write(f"âš¡ {analysis_type} ë¶„ì„ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                        
                        result = future.result(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                        
                        if result and not result.get("error"):
                            results[f"{analysis_type}_analysis"] = result
                            st.success(f"âœ… {analysis_type} ë¶„ì„ ì™„ë£Œ!")
                        else:
                            st.error(f"âŒ {analysis_type} ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                        
                        completed_count += 1
                        progress_placeholder.progress(completed_count / total_analyses)
                        
                    except Exception as e:
                        st.error(f"âŒ {analysis_type} ë¶„ì„ ì¤‘ ì˜ˆì™¸: {str(e)}")
                        completed_count += 1
                        progress_placeholder.progress(completed_count / total_analyses)
        
            # ìµœì¢… ì²˜ë¦¬
            progress_placeholder.empty()
            status_placeholder.empty()
            
            if results:
                st.session_state.analysis_results = results
                st.success("ğŸ‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.current_step = 4
                st.rerun()
            else:
                st.error("âŒ ëª¨ë“  ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                
                
            # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.write("---")
            st.write("### ğŸ’¾ ê²°ê³¼ ì €ì¥")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ“„ JSONìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"):
                    self._download_results_as_json(results)
            
            with col2:
                if st.button("ğŸ”„ ìƒˆ ë¶„ì„ ì‹œì‘"):
                    # ì„¸ì…˜ ì´ˆê¸°í™”
                    for key in ['analysis_plan', 'plan_approved', 'analysis_results']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.session_state.current_step = 1
                    st.rerun()